{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nivapy3 as nivapy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating fluxes using NivaPy\n",
    "\n",
    "Nivapy includes some simple functions for estimating riverine fluxes (also know as \"loads\"). This notebook creates a synthetic dataset based on discharge data from Langtjern and compares the various methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Read Langtjern discharge data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV data\n",
    "csv_path = r\"/home/jovyan/dstoolkit_examples/data/csv/langtjern_daily_flows.csv\"\n",
    "df = pd.read_csv(csv_path, parse_dates=True, index_col=0)\n",
    "\n",
    "# Linear interp. of missing data\n",
    "df.interpolate(method=\"linear\", inplace=True)\n",
    "\n",
    "# Flux functions require column named 'flow_m3/s'\n",
    "df.rename({\"flow_m3ps\": \"flow_m3/s\"}, inplace=True, axis=\"columns\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create \"fake\" concentration data\n",
    "\n",
    "We assume a log-log relationship between discharge and concentration (which is often theorised and *sometimes* observed in reality). The aim is just to generate a vaguely plausible timeseries of daily concentrations that can be used as a reference.\n",
    "\n",
    "$$log(C) = m * log(Q) + log(\\alpha) + \\epsilon$$\n",
    "\n",
    "where $\\epsilon \\sim \\mathcal{N}(0,\\,\\sigma^{2})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fake data\n",
    "m = 0.3\n",
    "alpha = 2\n",
    "sigma = 0.1\n",
    "\n",
    "# Calculate concentrations\n",
    "np.random.seed(0)\n",
    "df[\"par_mg/l\"] = 10 ** (\n",
    "    m * np.log10(df[\"flow_m3/s\"])\n",
    "    + np.log10(alpha)\n",
    "    + np.random.normal(loc=0, scale=sigma, size=len(df[\"flow_m3/s\"]))\n",
    ")\n",
    "\n",
    "df.plot(subplots=True, figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Estimate \"true\" fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"True\" flux\n",
    "df[\"true_flux_kg\"] = 1000 * 24 * 60 * 60 * df[\"flow_m3/s\"] * df[\"par_mg/l\"] / 1e6\n",
    "ann_true_df = df.resample(\"YE\").sum()[[\"true_flux_kg\"]]\n",
    "ann_true_df.index = ann_true_df.index.year\n",
    "ann_true_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Estimate fluxes with NivaPy\n",
    "\n",
    "### 4.1. Using all data\n",
    "\n",
    "Using the \"full\" series should give similar results to the \"true\" series (except when `method='simple_means'`, which is very biased). This isn't very useful, but should test for implementation errors in the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get help for nivapy flux estimation methods\n",
    "nivapy.stats.estimate_fluxes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datasets\n",
    "q_df = df[[\"flow_m3/s\"]].copy()\n",
    "conc_df = df[[\"par_mg/l\"]].copy()\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over methods\n",
    "for method in [\n",
    "    \"linear_interpolation\",\n",
    "    \"simple_means\",\n",
    "    \"log_log_linear_regression\",\n",
    "    \"ospar_annual\",\n",
    "]:\n",
    "    print(f\"Processing: {method}\")\n",
    "    # Estimate fluxes\n",
    "    flux_df = nivapy.stats.estimate_fluxes(\n",
    "        q_df, conc_df, base_freq=\"D\", agg_freq=\"YE\", method=method\n",
    "    )\n",
    "\n",
    "    # Delete flow vol, as interested in TOC\n",
    "    if method != \"ospar_annual\":\n",
    "        del flux_df[\"flow_m3\"]\n",
    "\n",
    "        # Convert date-times to integer years\n",
    "        flux_df.index = flux_df.index.year\n",
    "\n",
    "    # Rename col with method name for later\n",
    "    flux_df.columns = [method]\n",
    "\n",
    "    # Add to results\n",
    "    df_list.append(flux_df)\n",
    "\n",
    "# Merge results\n",
    "flux_df = pd.concat(df_list, axis=\"columns\")\n",
    "\n",
    "flux_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results compare well to the true/reference fluxes above, which suggests the code is working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Consider only monthly sampling\n",
    "\n",
    "What if we include only every 30th observation from the concentration data (i.e. approximately monthly sampling)? This is a more realistic test of the statistical properties of each algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract datasets\n",
    "q_df = df[[\"flow_m3/s\"]].copy()\n",
    "conc_df = df[[\"par_mg/l\"]].copy()\n",
    "\n",
    "# Use every 30th conc measurement\n",
    "conc_df = pd.concat([q_df, conc_df[::30]], axis=\"columns\")[[\"par_mg/l\"]]\n",
    "\n",
    "# Container for results\n",
    "df_list = []\n",
    "\n",
    "# Loop over methods\n",
    "for method in [\n",
    "    \"linear_interpolation\",\n",
    "    \"simple_means\",\n",
    "    \"log_log_linear_regression\",\n",
    "    \"ospar_annual\",\n",
    "]:\n",
    "    print(f\"Processing: {method}\")\n",
    "    # Estimate fluxes\n",
    "    flux_df = nivapy.stats.estimate_fluxes(\n",
    "        q_df, conc_df, base_freq=\"D\", agg_freq=\"YE\", method=method\n",
    "    )\n",
    "\n",
    "    # Delete flow vol, as interested in TOC\n",
    "    if method != \"ospar_annual\":\n",
    "        del flux_df[\"flow_m3\"]\n",
    "\n",
    "        # Convert date-times to integer years\n",
    "        flux_df.index = flux_df.index.year\n",
    "\n",
    "    # Rename col with method name for later\n",
    "    flux_df.columns = [method]\n",
    "\n",
    "    # Add to results\n",
    "    df_list.append(flux_df)\n",
    "\n",
    "# Merge results\n",
    "flux_df = pd.concat(df_list, axis=\"columns\")\n",
    "\n",
    "flux_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `method='log_log_linear_regression'` does a good job of estimating the correct regression coefficients here: $m = 0.3$ and $\\alpha = 2 = 10^{0.3}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Compare estimates to true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 6))\n",
    "ann_true_df.plot(ax=ax, lw=2, c=\"k\")\n",
    "flux_df.plot(ax=ax, style=\"--\")\n",
    "_ = ax.set_ylabel(\"Flux in kg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsurprisingly, the log-log regression method works very well here, because the \"fake\" data were generated by assuming a (noisy) log-log relationship, so the $R^2$ value is very high in this example compared to what is usually observed in reality. The OSPAR approach is also reasonable (although it overestimates in 2006 for some reason), while the other two methods tend to underestimate fluxes. This is largely as expected from statistical theory.\n",
    "\n",
    "A more detailed understanding of the performance of each algorithm could be obtained by **bootstrap resampling** the synthetic concentration dataset, but this is not covered here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
