{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from pandas import merge\n",
    "from pyniva import PUB_META, PUB_TSB, Vessel, token2header\n",
    "import datetime\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Color Fantasy data 1.1.2019 - 30.9.2020\n",
    "\n",
    "*Dag Hjermann (based on Zofia Rudjord's code)*  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_to_token = \"/home/jovyan/shared/common/01_datasets/tokens/niva-service-account.json\"\n",
    "HEADER = token2header(path_to_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get avaliable vessels / data sources  \n",
    "To check which Vessels have associated data, run the part below. Some of the abbreviations are  \n",
    "* FA - *Color Fantasy* (Oslo - Kiel)  \n",
    "* TF - *Trollfjord* (Hurtigruten, Bergen - Kirkenes)  \n",
    "* NO - *Norbjørn* (Tromsø - Svalbard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "boat = [v for v in Vessel.list(PUB_META, header=HEADER)]\n",
    "print(*[b.path for b in boat], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Fantasy (Oslo - Kiel): Get available measurements/sensors   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you uncomment the \"print\" part of the snippet below (long output!), you will see all avalilable time series from this vessel. You may findfor instance want the following time series:   \n",
    "* FA/ferrybox/INLET/TEMPERATURE  \n",
    "* FA/ferrybox/CTD/SALINITY  \n",
    "* FA/ferrybox/INLET/OXYGEN/CONCENTRATION  \n",
    "* FA/ferrybox/SYSTEM/OBSTRUCTION  \n",
    "* FA/ferrybox/SYSTEM/PUMP *(0 if the water pump is not running and the system doesn't work, 1 if the pump is running)* \n",
    "* FA/ferrybox/SYSTEM/TRIP_NUMBER *(consecutive numbers for every trip to/from Oslo)*   \n",
    "  \n",
    "(Longitude + latitude are metadata and will be downloaded separately afterwards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "platform_code = \"FA\"\n",
    "first_n_measurements = -1  # = -1 will list all measurments\n",
    "FA = [v for v in boat if v.path == platform_code][0]\n",
    "measurements = FA.get_all_tseries(PUB_META, header=HEADER)\n",
    "# print(*[m.path for m in measurements][:first_n_measurements], sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color Fantasy (Oslo - Kiel): Download data    \n",
    "We will download the data for May 2020. The part below downloads data for each of the time series below and stores the result in a list called `data_list`  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FA/ferrybox/INLET/TEMPERATURE\n",
      "FA/ferrybox/CTD/SALINITY\n",
      "FA/ferrybox/INLET/OXYGEN/CONCENTRATION\n",
      "FA/ferrybox/CHLA_FLUORESCENCE/ADJUSTED\n",
      "FA/ferrybox/SYSTEM/OBSTRUCTION\n",
      "FA/ferrybox/SYSTEM/PUMP\n",
      "FA/ferrybox/SYSTEM/TRIP_NUMBER\n"
     ]
    }
   ],
   "source": [
    "start_time = \"2020-05-01T00:00:00\"\n",
    "end_time = \"2020-06-01T00:00:00\"\n",
    "\n",
    "paths = ['FA/ferrybox/INLET/TEMPERATURE',\n",
    "         'FA/ferrybox/CTD/SALINITY',\n",
    "         'FA/ferrybox/INLET/OXYGEN/CONCENTRATION',\n",
    "         'FA/ferrybox/CHLA_FLUORESCENCE/ADJUSTED',\n",
    "         'FA/ferrybox/SYSTEM/OBSTRUCTION',  \n",
    "         'FA/ferrybox/SYSTEM/PUMP',\n",
    "         'FA/ferrybox/SYSTEM/TRIP_NUMBER'\n",
    "        ]\n",
    "\n",
    "# Make empty data list\n",
    "data_list = []\n",
    "\n",
    "# Go through all data sets listed in paths  \n",
    "# For each, we go through all measurements, and if its's the right one\n",
    "#   download the data and add to 'data_list'\n",
    "for i in range(0, len(paths),1):\n",
    "    print(paths[i])\n",
    "    for m in measurements:\n",
    "        if m.path == paths[i]:\n",
    "            data = m.get_tseries(\n",
    "                PUB_TSB,\n",
    "                header=HEADER,\n",
    "                noqc=True,\n",
    "                dt=0,\n",
    "                start_time=start_time,\n",
    "                end_time=end_time,\n",
    "                )\n",
    "            data_list.append(data)  # add data set to data_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check one element of `data_list`  \n",
    "Each of these lists contains a date set with two columns, where the first is time (given as date + time in UTZ time zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     obstruction\n",
      "time                            \n",
      "2020-05-01 00:00:18            0\n",
      "2020-05-01 00:01:18            0\n",
      "2020-05-01 00:02:18            0\n",
      "2020-05-01 00:03:18            0\n",
      "2020-05-01 00:04:18            0\n",
      "...                          ...\n",
      "2020-05-31 23:55:20            0\n",
      "2020-05-31 23:56:20            0\n",
      "2020-05-31 23:57:21            0\n",
      "2020-05-31 23:58:21            0\n",
      "2020-05-31 23:59:21            0\n",
      "\n",
      "[44554 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data_list[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coordinates   \n",
    "We use the ´start_time´ and ´end_time´ given above  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     longitude  latitude\n",
      "time                                    \n",
      "2020-05-01 00:00:18     10.746   59.9046\n",
      "2020-05-01 00:01:18     10.746   59.9046\n",
      "2020-05-01 00:02:18     10.746   59.9046\n",
      "2020-05-01 00:03:18     10.746   59.9046\n",
      "2020-05-01 00:04:18     10.746   59.9046\n",
      "...                        ...       ...\n",
      "2020-05-31 23:55:20     10.746   59.9046\n",
      "2020-05-31 23:56:20     10.746   59.9046\n",
      "2020-05-31 23:57:21     10.746   59.9046\n",
      "2020-05-31 23:58:21     10.746   59.9046\n",
      "2020-05-31 23:59:21     10.746   59.9046\n",
      "\n",
      "[44554 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# start_time = \"2019-01-01T00:00:00\"\n",
    "# end_time = \"2020-01-31T00:00:00\"\n",
    "path = platform_code + \"/gpstrack\"\n",
    "for m in measurements:\n",
    "    if m.path == path:\n",
    "        gpsdata = m.get_tseries(\n",
    "            PUB_TSB,\n",
    "            header=HEADER,\n",
    "            noqc=True,\n",
    "            dt=0,\n",
    "            start_time=start_time,\n",
    "            end_time=end_time,\n",
    "        )\n",
    "        \n",
    "print(gpsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge to a single data set \n",
    "We use the ´time´ for merging the data sets together \"side-by-side\", so we end with a data set with one line per time point and one column per variable  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     longitude  latitude  temperature  obstruction  pump  \\\n",
      "time                                                                       \n",
      "2020-05-01 00:00:18     10.746   59.9046        8.141            0     1   \n",
      "2020-05-01 00:01:18     10.746   59.9046        8.111            0     1   \n",
      "2020-05-01 00:02:18     10.746   59.9046        8.099            0     1   \n",
      "2020-05-01 00:03:18     10.746   59.9046        8.253            0     1   \n",
      "2020-05-01 00:04:18     10.746   59.9046        8.204            0     1   \n",
      "...                        ...       ...          ...          ...   ...   \n",
      "2020-05-31 23:55:20     10.746   59.9046       12.339            0     1   \n",
      "2020-05-31 23:56:20     10.746   59.9046       12.280            0     1   \n",
      "2020-05-31 23:57:21     10.746   59.9046       12.333            0     1   \n",
      "2020-05-31 23:58:21     10.746   59.9046       12.339            0     1   \n",
      "2020-05-31 23:59:21     10.746   59.9046       12.248            0     1   \n",
      "\n",
      "                     count  \n",
      "time                        \n",
      "2020-05-01 00:00:18  13429  \n",
      "2020-05-01 00:01:18  13429  \n",
      "2020-05-01 00:02:18  13429  \n",
      "2020-05-01 00:03:18  13429  \n",
      "2020-05-01 00:04:18  13429  \n",
      "...                    ...  \n",
      "2020-05-31 23:55:20  18749  \n",
      "2020-05-31 23:56:20  18749  \n",
      "2020-05-31 23:57:21  18749  \n",
      "2020-05-31 23:58:21  18749  \n",
      "2020-05-31 23:59:21  18749  \n",
      "\n",
      "[44554 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Start with just gpsdata  \n",
    "data_merged = gpsdata\n",
    "\n",
    "# Go through the data list and add one by one  \n",
    "# We use left join, as data without longitude and latitude are not very useful  \n",
    "for data_variable in data_list:\n",
    "    data_merged = merge(data_merged, data_variable, how = \"left\", on = \"time\")\n",
    "\n",
    "print(data_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the result to a csv (text) file  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_merged.to_csv(\"pydata_Fantasy_May2019.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
