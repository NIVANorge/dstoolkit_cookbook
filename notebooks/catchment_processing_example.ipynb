{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from IPython.display import display\n",
    "from rasterstats import zonal_stats\n",
    "\n",
    "import nivapy3 as nivapy\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with catchment boundaries\n",
    "\n",
    "The JupyterHub's integrated PostGIS database incorporates [a range of useful spatial datasets](https://github.com/NIVANorge/niva_jupyter_hub/blob/master/postgis_db/postgis_db_dataset_summary.md), including catchment boundaries that have been previously delineated for other projects (mostly by José-Luis Guerrero). This notebook provides some illustrative examples of how to work with catchment data on the JupyterHub."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Connect to PostGIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng = nivapy.da.connect_postgis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. List projects for which catchments are available\n",
    "\n",
    "Use the function `nivapy.da.select_jhub_projects` to view a list of all projects for which catchments have been delineated and added to the database. The list is limited at present, but will expand over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show projects in database\n",
    "with pd.option_context(\"display.max_colwidth\", -1):\n",
    "    proj_df = nivapy.da.select_jhub_projects(eng)\n",
    "    display(proj_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get catchment boundaries and outflow locations for projects of interest\n",
    "\n",
    "`nivapy.da.select_jhub_project_catchments` accepts a list of projects IDs (from the table above) and returns catchment geospatial data for all the stations associated with those projects. Two geodataframes are returned: the first (`stn_gdf` in the example below) lists the point data defining the stations. Note that, where available, these co-ordinates are for the **outflow points** used to generate the catchmewnt boundaries and **not the original station co-ordinates** (original co-ordinates should be available in either RESA or Aquamonitor and are not duplicated here unless the outflow co-ordinates are unknown); the second geodataframe (`cat_gdf` in the example below) contains the catchment polygons themselves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get catchment data for 1000 Lakes 2019\n",
    "stn_gdf, cat_gdf = nivapy.da.select_jhub_project_catchments([4], eng)\n",
    "\n",
    "stn_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. \"Quickmaps\" of all station outflows\n",
    "\n",
    "Use NivaPy's `quickmap` function to quickly visualise the spatial distribution of outflow points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nivapy.spatial.quickmap(\n",
    "    stn_gdf, cluster=True, kartverket=True, aerial_imagery=True, popup=\"station_code\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. \"Quickmaps\" for individual catchments\n",
    "\n",
    "The function `nivapy.spatial.catchment_boundary_quickmap` makes it easy to quickly check whether the boundary and outflow **for a single catchment** are reasonable. Pass in your station code of interest together with `cat_gdf` from above to quickly view a map of the watershed and outflow location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_code = \"412-5-1\"\n",
    "nivapy.spatial.catchment_boundary_quickmap(stn_code, cat_gdf, stn_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Linking with other vector datasets\n",
    "\n",
    "Other **vector** geospatial datasets available on the JupyterHub are listed [here](https://github.com/NIVANorge/niva_jupyter_hub/blob/master/postgis_db/postgis_db_dataset_summary.md). These can be combined with the catchment data in a variety of ways. The examples here are simple, but *not necessarily the most computationally efficient*.\n",
    "\n",
    "For example, suppose we are interested in data for station `101-2-7` (Hokksjøen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stn_code = \"101-2-7\"\n",
    "cat_gdf.query(\"station_code == @stn_code\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Check catchment boundary looks reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First plot the catchment to check it looks reasonable\n",
    "nivapy.spatial.catchment_boundary_quickmap(stn_code, cat_gdf, stn_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Get rivers and lakes for the same region (bounding box)\n",
    "\n",
    "Remember to check your co-ordinate systems match before doing any spatial processing. The code below converts everything to WGS84-based UTM Zone 33N, which is a good general choice for Norwegian data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get catchment of interest and reproject\n",
    "clip_gdf = cat_gdf.query(\"station_code == @stn_code\").to_crs(32633)\n",
    "\n",
    "# Get the river network and reproject\n",
    "riv_gdf = nivapy.da.read_postgis(\n",
    "    \"physical\", \"norway_nve_elvis_river_network_line\", eng, clip=clip_gdf,\n",
    ").to_crs(32633)\n",
    "\n",
    "# Get lakes and reproject\n",
    "lake_gdf = nivapy.da.read_postgis(\n",
    "    \"physical\", \"norway_nve_innsjo_poly\", eng, clip=clip_gdf,\n",
    ").to_crs(32633)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple map\n",
    "ax = lake_gdf.plot(facecolor=\"lightblue\", edgecolor=\"k\", figsize=(10, 10))\n",
    "riv_gdf.plot(ax=ax, edgecolor=\"b\")\n",
    "clip_gdf.plot(ax=ax, facecolor=\"none\", edgecolor=\"k\", lw=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing this to the \"quickmap\" above shows that this is the same data as used on Kartverkete's N50 map series, except we now have the actual geospatial data to work with, not just the base image from the Kartverket WMS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Land cover\n",
    "\n",
    "We can extract land cover information in the same way. The example below uses Corine 2018, but a [range of other datasets](https://github.com/NIVANorge/niva_jupyter_hub/blob/master/postgis_db/postgis_db_dataset_summary.md) are also available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract CORINE-2018 land cover, clipping to the specified catchment\n",
    "lu_gdf = nivapy.da.read_postgis(\n",
    "    \"physical\", \"norway_nibio_corine_2018_poly\", eng, clip=clip_gdf,\n",
    ").to_crs(32633)\n",
    "\n",
    "# Get top level class from Corine\n",
    "lu_gdf[\"main_class\"] = lu_gdf[\"klasse\"].str[:3]\n",
    "\n",
    "# Intersect with catchment\n",
    "lu_gdf = gpd.overlay(lu_gdf, clip_gdf, how=\"intersection\")\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "\n",
    "lu_gdf.plot(\n",
    "    column=\"main_class\", legend=True, legend_kwds={\"bbox_to_anchor\": (1.2, 1)}, ax=ax,\n",
    ")\n",
    "\n",
    "clip_gdf.plot(edgecolor=\"k\", facecolor=\"none\", ax=ax, lw=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarise land use statistics\n",
    "lu_gdf = lu_gdf.dissolve([\"klasse\"])[[\"norsk\", \"english\", \"geometry\"]]\n",
    "lu_gdf[\"area_km2\"] = lu_gdf[\"geometry\"].area / 1e6\n",
    "lu_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Linking with raster datasets\n",
    "\n",
    "To summarise raster datasets based on catchment polygons we can use the [`rasterio`](https://rasterio.readthedocs.io/en/latest/index.html) and [`rasterstats`](https://pythonhosted.org/rasterstats/index.html) packages.\n",
    "\n",
    "**Important note:** You *must* make sure the raster and vector datasets have the same co-ordinate system (datum, projection etc.). `rasterstats` performs calculations on a Cartesian grid, which assumes the spatial reference information in both datasets is the same.\n",
    "\n",
    "The example below calculates summary elevation statistics for each catchment in the 1000 Lakes dataset based on Kartverket's 50 m resolution DEM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check CRS of DEM\n",
    "dem_path = r\"/home/jovyan/shared/01_datasets/spatial/norway_kartverket_50m_dem.tif\"\n",
    "with rasterio.open(dem_path) as src:\n",
    "    print(src.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DEM uses ETRS89-based UTM zone 33N (EPSG 25833). This is very similar - but not identical - to WGS84-based UTM Zone 33N (EPSG 32633), which we have used above for the catchment data. The easiest way to proceed is therefore to **reproject the catchments to EPSG 25833** to match the DEM.\n",
    "\n",
    "The code below calculates a variety of summary statistics (in this case \"min\", \"max\", \"median\" and \"mean\" elevation) for just a single catchment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal stats for a single catchment\n",
    "stats = zonal_stats(\n",
    "    clip_gdf[\"geom\"].to_crs(25833), dem_path, stats=[\"min\", \"max\", \"median\", \"mean\"]\n",
    ")\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to process all 1001 catchments in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zonal stats for all catchments\n",
    "stats = zonal_stats(\n",
    "    cat_gdf[\"geom\"].to_crs(25833), dem_path, stats=[\"min\", \"max\", \"median\", \"mean\"]\n",
    ")\n",
    "\n",
    "# Convert results to dataframe and join station names etc.\n",
    "stats = pd.DataFrame(stats)\n",
    "stats = pd.concat(\n",
    "    [cat_gdf[[\"station_id\", \"station_code\", \"station_name\"]], stats], axis=\"columns\"\n",
    ")\n",
    "\n",
    "stats.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
